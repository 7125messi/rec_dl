{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单易用，同时支持多种推荐算法\n",
    "* 基础算法/baseline algorithms\n",
    "* 基于近邻方法(协同过滤)/neighborhood methods\n",
    "* 矩阵分解方法/matrix factorization-based (SVD, PMF, SVD++, NMF)\n",
    "\n",
    "算法类名\t说明\n",
    "\n",
    "**random_pred.NormalPredictor**\tAlgorithm predicting a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "\n",
    "**baseline_only.BaselineOnly**\tAlgorithm predicting the baseline estimate for given user and item.\n",
    "\n",
    "**knns.KNNBasic**\tA basic collaborative filtering algorithm.\n",
    "\n",
    "**knns.KNNWithMeans**\tA basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "\n",
    "**knns.KNNBaseline**\tA basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "\n",
    "**matrix_factorization.SVD**\tThe famous SVD algorithm, as popularized by Simon Funk during the Netflix Prize.\n",
    "\n",
    "**matrix_factorization.SVDpp**\tThe SVD++ algorithm, an extension of SVD taking into account implicit ratings.\n",
    "\n",
    "**matrix_factorization.NMF**\tA collaborative filtering algorithm based on Non-negative Matrix Factorization.\n",
    "\n",
    "**slope_one.SlopeOne**\tA simple yet accurate collaborative filtering algorithm.\n",
    "\n",
    "**co_clustering.CoClustering**\tA collaborative filtering algorithm based on co-clustering.\n",
    "\n",
    "# 其中基于近邻的方法(协同过滤)可以设定不同的度量准则\n",
    "\n",
    "相似度度量标准\t度量标准说明\n",
    "\n",
    "**cosine**\tCompute the cosine similarity between all pairs of users (or items).\n",
    "\n",
    "**msd**\tCompute the Mean Squared Difference similarity between all pairs of users (or items).\n",
    "\n",
    "**pearson**\tCompute the Pearson correlation coefficient between all pairs of users (or items).\n",
    "\n",
    "**pearson_baseline**\tCompute the (shrunk) Pearson correlation coefficient between all pairs of users (or items) using \n",
    "\n",
    "**baselines** for centering instead of means.\n",
    "\n",
    "# 支持不同的评估准则\n",
    "\n",
    "评估准则\t准则说明\n",
    "\n",
    "**rmse**\tCompute RMSE (Root Mean Squared Error).\n",
    "\n",
    "**mae**\tCompute MAE (Mean Absolute Error).\n",
    "\n",
    "**fcp**\tCompute FCP (Fraction of Concordant Pairs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD算法示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to /Users/zhaoyadong/.surprise_data/ml-100k\n",
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9320  0.9384  0.9327  0.9429  0.9340  0.9360  0.0041  \n",
      "MAE (testset)     0.7330  0.7406  0.7365  0.7420  0.7378  0.7380  0.0031  \n",
      "Fit time          4.27    4.47    4.49    4.48    4.47    4.44    0.08    \n",
      "Test time         0.17    0.13    0.12    0.15    0.12    0.14    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93196378, 0.93842642, 0.9327256 , 0.94291277, 0.93403339]),\n",
       " 'test_mae': array([0.73302103, 0.74057704, 0.73654968, 0.7419691 , 0.7377506 ]),\n",
       " 'fit_time': (4.268312931060791,\n",
       "  4.472671031951904,\n",
       "  4.493643045425415,\n",
       "  4.479049921035767,\n",
       "  4.474570989608765),\n",
       " 'test_time': (0.17134571075439453,\n",
       "  0.12970495223999023,\n",
       "  0.1226348876953125,\n",
       "  0.15154194831848145,\n",
       "  0.12108802795410156)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed).\n",
    "# /Users/zhaoyadong/.surprise_data/ml-100k   下载位置\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入自己的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zhaoyadong/.surprise_data/ml-100k/ml-100k/u.data'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate,train_test_split\n",
    "\n",
    "# 指定文件所在路径\n",
    "file_path = os.path.expanduser('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.reader.Reader at 0x11c3eb5d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 告诉文本阅读器，文本的格式是怎么样的\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x11331e910>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用不同的推荐系统算法进行建模比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.52112873, 1.52385424, 1.52311202]),\n",
       " 'test_mae': array([1.22258649, 1.22541031, 1.22553219]),\n",
       " 'fit_time': (0.10647702217102051, 0.12001776695251465, 0.13048481941223145),\n",
       " 'test_time': (0.275972843170166, 0.27295994758605957, 0.20937275886535645)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 使用NormalPredictor\n",
    "from surprise import NormalPredictor\n",
    "from surprise.model_selection import cross_validate\n",
    "algo = NormalPredictor()\n",
    "cross_validate(algo, data, measures=['RMSE','MAE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94493839, 0.94228404, 0.95453153]),\n",
       " 'test_mae': array([0.74860023, 0.7482294 , 0.75718467]),\n",
       " 'fit_time': (0.2533440589904785, 0.2319469451904297, 0.2509419918060303),\n",
       " 'test_time': (0.21754813194274902, 0.23023319244384766, 0.23073101043701172)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 使用BaselineOnly\n",
    "from surprise import BaselineOnly\n",
    "from surprise.model_selection import cross_validate\n",
    "algo = BaselineOnly()\n",
    "cross_validate(algo, data, measures=['RMSE','MAE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.98133296, 0.99188314, 0.98792539]),\n",
       " 'test_mae': array([0.77566632, 0.78575441, 0.77919485]),\n",
       " 'fit_time': (0.2804989814758301, 0.2587110996246338, 0.25031518936157227),\n",
       " 'test_time': (4.2373881340026855, 4.165133714675903, 4.306735992431641)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 使用基础版协同过滤\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "algo = KNNBasic()\n",
    "cross_validate(algo, data, measures=['RMSE','MAE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.95731906, 0.95732487, 0.95480123]),\n",
       " 'test_mae': array([0.75462424, 0.75545846, 0.75230773]),\n",
       " 'fit_time': (0.3175926208496094, 0.2771129608154297, 0.28166699409484863),\n",
       " 'test_time': (4.626938104629517, 4.3745622634887695, 4.506859064102173)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 使用均值协同过滤\n",
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import cross_validate\n",
    "algo = KNNWithMeans()\n",
    "cross_validate(algo, data, measures=['RMSE','MAE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.9438566 , 0.93318902, 0.9321911 ]),\n",
       " 'test_mae': array([0.74604609, 0.73321011, 0.73435405]),\n",
       " 'fit_time': (0.5125937461853027, 0.40860581398010254, 0.4391019344329834),\n",
       " 'test_time': (5.216365098953247, 5.137558221817017, 5.172612190246582)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 使用协同过滤baseline\n",
    "from surprise import KNNBaseline\n",
    "from surprise.model_selection import cross_validate\n",
    "algo = KNNBaseline()\n",
    "cross_validate(algo, data, measures=['RMSE','MAE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94885668, 0.94459868, 0.94461429]),\n",
       " 'test_mae': array([0.74998314, 0.74544288, 0.74404708]),\n",
       " 'fit_time': (3.548034906387329, 3.535391092300415, 3.7439491748809814),\n",
       " 'test_time': (0.20096206665039062, 0.27524304389953613, 0.3032660484313965)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 使用SVD\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE','MAE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.92375337, 0.93268092, 0.93254211]),\n",
       " 'test_mae': array([0.72516722, 0.7333364 , 0.7326444 ]),\n",
       " 'fit_time': (108.41236877441406, 107.79821062088013, 108.69368195533752),\n",
       " 'test_time': (5.014692068099976, 4.52144193649292, 5.16087007522583)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 使用SVD++（耗时）\n",
    "from surprise import SVDpp\n",
    "from surprise.model_selection import cross_validate\n",
    "algo = SVDpp()\n",
    "cross_validate(algo, data, measures=['RMSE','MAE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.97079889, 0.97108764, 0.97510558]),\n",
       " 'test_mae': array([0.76379115, 0.7641557 , 0.76433039]),\n",
       " 'fit_time': (3.9752910137176514, 4.075232982635498, 3.928323984146118),\n",
       " 'test_time': (0.24855399131774902, 0.2504160404205322, 0.23262906074523926)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 使用NMF\n",
    "from surprise import NMF\n",
    "from surprise.model_selection import cross_validate\n",
    "algo = NMF()\n",
    "cross_validate(algo, data, measures=['RMSE','MAE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模和存储模型\n",
    "\n",
    "## 1.用协同过滤构建模型并进行预测\n",
    "\n",
    "* movielens的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.9234231 , 0.92908341, 0.93160281]),\n",
       " 'test_mae': array([0.72610348, 0.72945552, 0.72817546]),\n",
       " 'fit_time': (1.2767589092254639, 1.2908000946044922, 1.1555171012878418),\n",
       " 'test_time': (5.418834209442139, 5.452134847640991, 5.47606897354126)}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import (absolute_import, division, print_function,unicode_literals)\n",
    "import os\n",
    "import io\n",
    "from surprise import KNNBaseline\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# 指定文件所在路径\n",
    "file_path = os.path.expanduser('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "# 告诉文本阅读器，文本的格式是怎么样的\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "# 加载数据\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False} #相似度计算设定，使用皮尔逊相似度计算法，使用ItemCF的相似度计算\n",
    "algo = KNNBaseline(sim_options=sim_options) #使用KNNBaseline算法（一种CF算法）进行推荐系统构建\n",
    "cross_validate(algo, data, measures=['RMSE','MAE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38756778, -0.49873698, -0.07257962, ..., -0.07891285,\n",
       "        0.0410197 , -0.07891285])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.bsl_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.bu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1626,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.bx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.by.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.compute_baselines()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1626, 1626)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.compute_similarities().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.532677336613317"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.default_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/lib/python3.7/site-packages/surprise/prediction_algorithms/knns.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "algo.estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Train an algorithm on a given training set.\n",
       "\n",
       "This method is called by every derived class as the first basic step\n",
       "for training an algorithm. It basically just initializes some internal\n",
       "structures and set the self.trainset attribute.\n",
       "\n",
       "Args:\n",
       "    trainset(:obj:`Trainset <surprise.Trainset>`) : A training\n",
       "        set, as returned by the :meth:`folds\n",
       "        <surprise.dataset.Dataset.folds>` method.\n",
       "\n",
       "Returns:\n",
       "    self\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/lib/python3.7/site-packages/surprise/prediction_algorithms/knns.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "algo.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return the ``k`` nearest neighbors of ``iid``, which is the inner id\n",
       "of a user or an item, depending on the ``user_based`` field of\n",
       "``sim_options`` (see :ref:`similarity_measures_configuration`).\n",
       "\n",
       "As the similarities are computed on the basis of a similarity measure,\n",
       "this method is only relevant for algorithms using a similarity measure,\n",
       "such as the :ref:`k-NN algorithms <pred_package_knn_inpired>`.\n",
       "\n",
       "For a usage example, see the :ref:`FAQ <get_k_nearest_neighbors>`.\n",
       "\n",
       "Args:\n",
       "    iid(int): The (inner) id of the user (or item) for which we want\n",
       "        the nearest neighbors. See :ref:`this note<raw_inner_note>`.\n",
       "\n",
       "    k(int): The number of neighbors to retrieve.\n",
       "\n",
       "Returns:\n",
       "    The list of the ``k`` (inner) ids of the closest users (or items)\n",
       "    to ``iid``.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/lib/python3.7/site-packages/surprise/prediction_algorithms/algo_base.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "algo.get_neighbors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.min_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1626"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.n_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.n_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_ui\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Compute the rating prediction for given user and item.\n",
       "\n",
       "The ``predict`` method converts raw ids to inner ids and then calls the\n",
       "``estimate`` method which is defined in every derived class. If the\n",
       "prediction is impossible (e.g. because the user and/or the item is\n",
       "unkown), the prediction is set according to :meth:`default_prediction()\n",
       "<surprise.prediction_algorithms.algo_base.AlgoBase.default_prediction>`.\n",
       "\n",
       "Args:\n",
       "    uid: (Raw) id of the user. See :ref:`this note<raw_inner_note>`.\n",
       "    iid: (Raw) id of the item. See :ref:`this note<raw_inner_note>`.\n",
       "    r_ui(float): The true rating :math:`r_{ui}`. Optional, default is\n",
       "        ``None``.\n",
       "    clip(bool): Whether to clip the estimation into the rating scale.\n",
       "        For example, if :math:`\\hat{r}_{ui}` is :math:`5.5` while the\n",
       "        rating scale is :math:`[1, 5]`, then :math:`\\hat{r}_{ui}` is\n",
       "        set to :math:`5`. Same goes if :math:`\\hat{r}_{ui} < 1`.\n",
       "        Default is ``True``.\n",
       "    verbose(bool): Whether to print details of the prediction.  Default\n",
       "        is False.\n",
       "\n",
       "Returns:\n",
       "    A :obj:`Prediction            <surprise.prediction_algorithms.predictions.Prediction>` object\n",
       "    containing:\n",
       "\n",
       "    - The (raw) user id ``uid``.\n",
       "    - The (raw) item id ``iid``.\n",
       "    - The true rating ``r_ui`` (:math:`\\hat{r}_{ui}`).\n",
       "    - The estimated rating (:math:`\\hat{r}_{ui}`).\n",
       "    - Some additional details about the prediction that might be useful\n",
       "      for later analysis.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/lib/python3.7/site-packages/surprise/prediction_algorithms/algo_base.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "algo.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1626, 1626)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'pearson_baseline', 'user_based': False}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.sim_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# 在协同过滤算法建模以后，根据一个item取回相似度最高的item，主要是用到algo.get_neighbors()这个函数 \n",
    "# 读取物品（电影）名称信息\n",
    "def read_item_names():\n",
    "    \"\"\"\n",
    "    获取电影名到电影id 和 电影id到电影名的映射\n",
    "    \"\"\"\n",
    "    file_name = (os.path.expanduser('~/.surprise_data/ml-100k/ml-100k/u.item'))\n",
    "    rid_to_name = {}\n",
    "    name_to_rid = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[1]\n",
    "            name_to_rid[line[1]] = line[0]\n",
    "    return rid_to_name,name_to_rid\n",
    "\n",
    "# 获取电影名到电影id 和 电影id到电影名的映射\n",
    "rid_to_name, name_to_rid = read_item_names()\n",
    "\n",
    "# 获得Toy Story电影的电影ID\n",
    "toy_story_raw_id = name_to_rid['Toy Story (1995)']\n",
    "print(toy_story_raw_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "# 通过Toy Story电影的电影ID获取该电影的推荐内部id\n",
    "toy_story_inner_id = algo.trainset.to_inner_iid(toy_story_raw_id)\n",
    "print(toy_story_inner_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoodFellas (1990)\n"
     ]
    }
   ],
   "source": [
    "# 获得电影ID=182电影名称\n",
    "name = rid_to_name['182']\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 298, 748, 373, 134, 436, 241, 164, 395, 397, 1026, 221, 689, 262, 151, 987, 259, 487, 269, 547]\n"
     ]
    }
   ],
   "source": [
    "# 获得Toy Story电影的相似（邻居）电影的ID集合(10个)\n",
    "toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=20)\n",
    "print(toy_story_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "与《Toy Story》最相似的10个电影是：\n",
      "Liar Liar (1997)\n",
      "Lion King, The (1994)\n",
      "That Thing You Do! (1996)\n",
      "Seven (Se7en) (1995)\n",
      "Jurassic Park (1993)\n",
      "Wizard of Oz, The (1939)\n",
      "Beauty and the Beast (1991)\n",
      "Raiders of the Lost Ark (1981)\n",
      "Star Trek: The Wrath of Khan (1982)\n",
      "Craft, The (1996)\n",
      "Army of Darkness (1993)\n",
      "Abyss, The (1989)\n",
      "Evil Dead II (1987)\n",
      "Empire Strikes Back, The (1980)\n",
      "Indiana Jones and the Last Crusade (1989)\n",
      "So I Married an Axe Murderer (1993)\n",
      "E.T. the Extra-Terrestrial (1982)\n",
      "Long Kiss Goodnight, The (1996)\n",
      "Princess Bride, The (1987)\n",
      "Mask, The (1994)\n"
     ]
    }
   ],
   "source": [
    "# 根据相似电影的内部电影ID获得实际电影ID\n",
    "toy_story_neighbors = (algo.trainset.to_raw_iid(inner_id) for inner_id in toy_story_neighbors)\n",
    "# 根据相似电影的实际电影ID获得实际电影名称\n",
    "toy_story_neighbors = (rid_to_name[rid] for rid in toy_story_neighbors)\n",
    "# 输出推荐结果\n",
    "print(\"与《Toy Story》最相似的10个电影是：\")\n",
    "for movie in toy_story_neighbors:\n",
    "    print(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 找到和用户A相似的N个用户\n",
    "## 3 找到和物品A相似的N个物品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "['241', '162', '80', '36', '61']\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "['1081', '1444', '842', '1110', '812', '626', '1150', '1334', '1327', '1346']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import KNNBasic\n",
    "from surprise import BaselineOnly\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# 1.item_user_rate_time.txt 数据格式 user item rating timestamp (用户id 物品id 评分 时间戳)\n",
    "# 2.数据读取 训练模型\n",
    "file_path = os.path.expanduser('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "surprise_data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "all_trainset = surprise_data.build_full_trainset()\n",
    "algo = KNNBasic(k=40,\n",
    "                min_k=3,\n",
    "                sim_options={\n",
    "                    'user_based': True})\n",
    "# sim_options={'name': 'cosine','user_based': True} cosine/msd/pearson/pearson_baseline\n",
    "algo.fit(all_trainset)\n",
    "\n",
    "# 3.找到相似用户\n",
    "def getSimilarUsers(top_k,u_id):\n",
    "    user_inner_id = algo.trainset.to_inner_uid(u_id)\n",
    "    user_neighbors = algo.get_neighbors(user_inner_id, k=top_k)\n",
    "    user_neighbors = (algo.trainset.to_raw_uid(inner_id) for inner_id in user_neighbors)\n",
    "    return user_neighbors\n",
    "print(list(getSimilarUsers(5,'196')))\n",
    "# ['241', '162', '80', '36', '61']\n",
    "\n",
    "# 4.找到相似物品 sim_options中的user_based设置为false，基于物品相似度进行计算\n",
    "item_algo = KNNBasic(k=40,\n",
    "                     min_k=3,\n",
    "                     sim_options={\n",
    "                         'user_based': False})\n",
    "# sim_options={'name': 'cosine','user_based': True} cosine/msd/pearson/pearson_baseline\n",
    "item_algo.fit(all_trainset)\n",
    "\n",
    "def getSimilarItems(top_k, item_id):\n",
    "    item_inner_id = item_algo.trainset.to_inner_iid(item_id)\n",
    "    item_neighbors = item_algo.get_neighbors(item_inner_id, k=top_k)\n",
    "    f_item_neighbors = (item_algo.trainset.to_raw_iid(inner_id)\n",
    "                        for inner_id in item_neighbors)\n",
    "    return f_item_neighbors\n",
    "print(list(getSimilarItems(10, '242')))\n",
    "# ['1081', '1444', '842', '1110', '812', '626', '1150', '1334', '1327', '1346']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
